{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Name: Human Activity Recognition (`HAR`) utilizing Long short-term memory (`LSTM`) for `PAMAP2`  & `OPPORTUNITY` Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODUCTION:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Introduction\n",
    "Nowadays deep learning and machine learning have become an important field that is making a significant contribution to sensor-based human activity recognition. Wearables are an early part of understanding the richness of human activity recognition. It has a wide range of applications in many fields such as intelligent systems, ambient assisted living, security surveillance, the manufacturing industry, sports support, social science, and surveying systems. The primary motive for these applications is the ability to automatically and precisely detect human activities from often small sensors embedded in wearables.\n",
    "Many approaches have been developed to solve the recognition problem and most machine learning algorithms and deep learning algorithms have been used in this field and evaluated through experiments. Wearables capture a person's activity dynamics by recording continuous measurements over time through different sensor channels and generating multi-channel time-series data streams. To analyze the recognition and classification of human physical activities (e.g. Walking, running, drinking, etc.) we propose that we implement different machine learning algorithms (Like Support Vector Machine, K-nearest Neighbor) and deep learning algorithms (such as Convolutional Neural Networks, LSTM) on 3 datasets which are OPPORTUNITY, UCI HAR, and PAMAP-2. With the help of these datasets our motive of comparing the accuracy and performance of the machine learning algorithm and deep learning algorithm in recognizing human daily physical activities.   \n",
    "There are some existing papers that work on human activity recognition individually with different datasets. Since we want to do a comparative analysis, we don't have a data collection problem, we will take data for our analysis from different online sites, and we will train and test the data. After that, we will use the data with different machine learning and deep learning algorithms to find out the performance or accuracy, and then we will compare which one gives better performance. \n",
    "In our study, we found that Daniel Rogen and his teammates used the OPPORTUNITY and Skoda datasets and their algorithms were CNN and LSTM for their model. In their research, they demonstrated the benefits of a deep architecture based on a combination of convolutional and LSTM recurrent layers to perform activity recognition from wearable sensors.\n",
    "Shaohua Wan and his teammates used a classification method based on a convolutional neural network (CNN), which uses a CNN to extract local features. Finally, CNN, LSTM, BLSTM, MLP, and SVM models are used on the UCI and Pamap2 datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Motivation\n",
    "Many studies have been conducted on solving human activity recognition (HAR) problems with wearables, and Knowledge has been greatly improved with end-to-end deep learning paradigms. Human activity recognition (HAR) using wearable sensors is currently the latest topic in Deep neural networks due to its many applications. Our main goal is to compare and analyze the results obtained by running various machine learning and deep learning algorithms with multiple datasets. Inspired by previous HAR research, our main task is to propose a new HAR framework built on multiple datasets and demonstrate its performance realization using a variety of deep learning and machine learning-based algorithms that generalize to wearable sensor datasets. We have seen many papers that have predicted performance or accuracy with deep learning or machine learning but have not analyzed it on a comparative basis so the idea came from there we will implement and analyze both cases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Related Works\n",
    "F. Attal et. al. (2015), suggest a review of different classification techniques used to recognize human activities from wearable inertial sensor data. Three main steps describe the activity recognition process: sensors' placement, data pre-processing and data classification. The HMM classifier is the one that gives the best results among unsupervised classification algorithms. <br>\n",
    "According to the study of Ordóñez and Roggen (2016), deep convolutional neural networks are suited to automate feature extraction from raw sensor inputs. However, human activities are made of complex sequences of motor movements. The framework can be applied to homogeneous sensor modalities, but can also fuse multimodal sensors to improve performance.<br>\n",
    "According to A. Murad et. al. (2017), adopting deep learning methods for human activity recognition has been effective in extracting discriminative features from raw input sequences acquired from body-worn sensors. We propose the use of deep recurrent neural networks for building recognition models that are capable of capturing long-range dependencies in variable-length input sequences.<br>\n",
    "M.M. Hasan et. al. (2018) suggest, human activity recognition has grabbed considerable attention from pattern recognition and human–computer interaction researchers due to its prominent applications such as smart home health care. The proposed approach was compared with traditional expression recognition approaches such as typical multiclass Support Vector Machine (SVM) and Artificial Neural Network (ANN).<br>\n",
    "Mobile edge computing is serving as a bridge to narrow the gaps between medical staff and patients. S. Wan’s (2020) paper designs a smartphone inertial accelerometer-based architecture for HAR. A real-time human activity classification method based on a convolutional neural network (CNN) is proposed.<br>\n",
    "Activity recognition can be seen as a machine learning chain with its particular data preprocessing technique. J. Suto et. al. (2020) examine the efficiency of previously used machine learning methods in real time by an Android-based, self-learning, activity recognition application which has been designed for this study.<br>\n",
    "Deep Stacked Multilayered Perceptron (DS-MLP) has been proposed in F. Rustam et. al. (2020) study for human activity recognition (HAR). This study uses sensor data from two low-cost sensors, gyroscope and accelerometer along with implementation of an Artificial Neural Network (ANN) for HAR.<br>\n",
    "According to A. Murad et. al. (2021), Human Activity Recognition (HAR) employing inertial motion data has gained considerable momentum in recent years, both in research and industrial applications. The HAR method is evaluated on a public smartphone-based dataset of UCI-HAR through various combinations of sample generation processes and validation protocols.<br>\n",
    "Many Artificial intelligence-based models are developed for activity recognition; however, these algorithms fail to extract spatial and temporal features. An extensive ablation study is performed over different machine learning and deep learning models to obtain the optimum solution for HAR. A new dataset is generated that is collected from 20 participants using the Kinect V2 sensor and contains 12 different classes of human activities in I. U. Khan’s study (2022).<br>\n",
    "<br>\n",
    "<img src=\".\\Data\\Img\\report_final.png\" alt=\"Related Works\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Research Objective\n",
    "The main objectives of this study is as follow: <br>\n",
    "•\t..............................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. DATA ANALYSIS:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1. DATA PREPROCESSING:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy import integrate\n",
    "from IPython.display import HTML, display\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t as the\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import tree\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', 70)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\".\\Data\\Img\\data_format.PNG\" alt=\"Data Format\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "list_of_files = ['PAMAP2_Dataset/Protocol/subject101.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject102.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject103.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject104.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject105.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject106.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject107.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject108.dat',\n",
    "                 'PAMAP2_Dataset/Protocol/subject109.dat' ]\n",
    "\n",
    "subjectID = [1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "activityIDdict = {0: 'transient',\n",
    "              1: 'lying',\n",
    "              2: 'sitting',\n",
    "              3: 'standing',\n",
    "              4: 'walking',\n",
    "              5: 'running',\n",
    "              6: 'cycling',\n",
    "              7: 'Nordic_walking',\n",
    "              9: 'watching_TV',\n",
    "              10: 'computer_work',\n",
    "              11: 'car driving',\n",
    "              12: 'ascending_stairs',\n",
    "              13: 'descending_stairs',\n",
    "              16: 'vacuum_cleaning',\n",
    "              17: 'ironing',\n",
    "              18: 'folding_laundry',\n",
    "              19: 'house_cleaning',\n",
    "              20: 'playing_soccer',\n",
    "              24: 'rope_jumping' }\n",
    "\n",
    "colNames = [\"timestamp\", \"activityID\",\"heartrate\"]\n",
    "\n",
    "IMUhand = ['handTemperature', \n",
    "           'handAcc16_1', 'handAcc16_2', 'handAcc16_3', \n",
    "           'handAcc6_1', 'handAcc6_2', 'handAcc6_3', \n",
    "           'handGyro1', 'handGyro2', 'handGyro3', \n",
    "           'handMagne1', 'handMagne2', 'handMagne3',\n",
    "           'handOrientation1', 'handOrientation2', 'handOrientation3', 'handOrientation4']\n",
    "\n",
    "IMUchest = ['chestTemperature', \n",
    "           'chestAcc16_1', 'chestAcc16_2', 'chestAcc16_3', \n",
    "           'chestAcc6_1', 'chestAcc6_2', 'chestAcc6_3', \n",
    "           'chestGyro1', 'chestGyro2', 'chestGyro3', \n",
    "           'chestMagne1', 'chestMagne2', 'chestMagne3',\n",
    "           'chestOrientation1', 'chestOrientation2', 'chestOrientation3', 'chestOrientation4']\n",
    "\n",
    "IMUankle = ['ankleTemperature', \n",
    "           'ankleAcc16_1', 'ankleAcc16_2', 'ankleAcc16_3', \n",
    "           'ankleAcc6_1', 'ankleAcc6_2', 'ankleAcc6_3', \n",
    "           'ankleGyro1', 'ankleGyro2', 'ankleGyro3', \n",
    "           'ankleMagne1', 'ankleMagne2', 'ankleMagne3',\n",
    "           'ankleOrientation1', 'ankleOrientation2', 'ankleOrientation3', 'ankleOrientation4']\n",
    "\n",
    "columns = colNames + IMUhand + IMUchest + IMUankle  #all columns in one list\n",
    "\n",
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PAMAP2_Dataset/Protocol/subject101.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m dataCollection \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m list_of_files:\n\u001b[1;32m----> 3\u001b[0m     procData \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_table(file, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39ms+\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m     procData\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m columns\n\u001b[0;32m      5\u001b[0m     procData[\u001b[39m'\u001b[39m\u001b[39msubject_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(file[\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Taimur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Taimur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Taimur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1289\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m   1274\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1275\u001b[0m     dialect,\n\u001b[0;32m   1276\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1285\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m},\n\u001b[0;32m   1286\u001b[0m )\n\u001b[0;32m   1287\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1289\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Taimur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Taimur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\Taimur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Taimur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PAMAP2_Dataset/Protocol/subject101.dat'"
     ]
    }
   ],
   "source": [
    "dataCollection = pd.DataFrame()\n",
    "for file in list_of_files:\n",
    "    procData = pd.read_table(file, header=None, sep='\\s+')\n",
    "    procData.columns = columns\n",
    "    procData['subject_id'] = int(file[-5])\n",
    "    dataCollection = pd.concat([dataCollection, procData], ignore_index=True)\n",
    "\n",
    "dataCollection.reset_index(drop=True, inplace=True)\n",
    "dataCollection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2872533 entries, 0 to 2872532\n",
      "Data columns (total 55 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   timestamp          float64\n",
      " 1   activityID         int64  \n",
      " 2   heartrate          float64\n",
      " 3   handTemperature    float64\n",
      " 4   handAcc16_1        float64\n",
      " 5   handAcc16_2        float64\n",
      " 6   handAcc16_3        float64\n",
      " 7   handAcc6_1         float64\n",
      " 8   handAcc6_2         float64\n",
      " 9   handAcc6_3         float64\n",
      " 10  handGyro1          float64\n",
      " 11  handGyro2          float64\n",
      " 12  handGyro3          float64\n",
      " 13  handMagne1         float64\n",
      " 14  handMagne2         float64\n",
      " 15  handMagne3         float64\n",
      " 16  handOrientation1   float64\n",
      " 17  handOrientation2   float64\n",
      " 18  handOrientation3   float64\n",
      " 19  handOrientation4   float64\n",
      " 20  chestTemperature   float64\n",
      " 21  chestAcc16_1       float64\n",
      " 22  chestAcc16_2       float64\n",
      " 23  chestAcc16_3       float64\n",
      " 24  chestAcc6_1        float64\n",
      " 25  chestAcc6_2        float64\n",
      " 26  chestAcc6_3        float64\n",
      " 27  chestGyro1         float64\n",
      " 28  chestGyro2         float64\n",
      " 29  chestGyro3         float64\n",
      " 30  chestMagne1        float64\n",
      " 31  chestMagne2        float64\n",
      " 32  chestMagne3        float64\n",
      " 33  chestOrientation1  float64\n",
      " 34  chestOrientation2  float64\n",
      " 35  chestOrientation3  float64\n",
      " 36  chestOrientation4  float64\n",
      " 37  ankleTemperature   float64\n",
      " 38  ankleAcc16_1       float64\n",
      " 39  ankleAcc16_2       float64\n",
      " 40  ankleAcc16_3       float64\n",
      " 41  ankleAcc6_1        float64\n",
      " 42  ankleAcc6_2        float64\n",
      " 43  ankleAcc6_3        float64\n",
      " 44  ankleGyro1         float64\n",
      " 45  ankleGyro2         float64\n",
      " 46  ankleGyro3         float64\n",
      " 47  ankleMagne1        float64\n",
      " 48  ankleMagne2        float64\n",
      " 49  ankleMagne3        float64\n",
      " 50  ankleOrientation1  float64\n",
      " 51  ankleOrientation2  float64\n",
      " 52  ankleOrientation3  float64\n",
      " 53  ankleOrientation4  float64\n",
      " 54  subject_id         int64  \n",
      "dtypes: float64(53), int64(2)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "dataCollection.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp                  0\n",
       "activityID                 0\n",
       "heartrate            2610265\n",
       "handTemperature        13141\n",
       "handAcc16_1            13141\n",
       "                      ...   \n",
       "ankleOrientation1      11749\n",
       "ankleOrientation2      11749\n",
       "ankleOrientation3      11749\n",
       "ankleOrientation4      11749\n",
       "subject_id                 0\n",
       "Length: 55, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of missing values in each column\n",
    "dataCollection.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimpute\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleImputer\n\u001b[0;32m      4\u001b[0m \u001b[39m# create an instance of the SimpleImputer class\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m imputer \u001b[39m=\u001b[39m SimpleImputer(missing_values\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan, strategy\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[39m# select the columns you want to impute\u001b[39;00m\n\u001b[0;32m      8\u001b[0m columns_to_impute \u001b[39m=\u001b[39m dataCollection\u001b[39m.\u001b[39mcolumns[dataCollection\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39many()]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# import the SimpleImputer class\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# create an instance of the SimpleImputer class\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# select the columns you want to impute\n",
    "columns_to_impute = dataCollection.columns[dataCollection.isnull().any()]\n",
    "\n",
    "# fit the imputer to the data\n",
    "imputer.fit(dataCollection[columns_to_impute])\n",
    "\n",
    "# transform the data\n",
    "dataCollection[columns_to_impute] = imputer.transform(dataCollection[columns_to_impute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataCollection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# reset the index\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataCollection\u001b[39m.\u001b[39mreset_index(drop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, inplace \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m dataCollection\u001b[39m.\u001b[39msample(\u001b[39m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataCollection' is not defined"
     ]
    }
   ],
   "source": [
    "# reset the index\n",
    "dataCollection.reset_index(drop = True, inplace = True)\n",
    "dataCollection.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataCollection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Count the number of missing values in each column\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataCollection\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39msum()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataCollection' is not defined"
     ]
    }
   ],
   "source": [
    "# Count the number of missing values in each column\n",
    "dataCollection.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.2. Exploratory Data Analysis (EDA):**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.3. LSTM model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import math\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# set the number of time steps\n",
    "n_steps = 128\n",
    "\n",
    "# set the number of features\n",
    "n_features = len(dataCollection.columns) - 1\n",
    "\n",
    "# split the data into input and output\n",
    "X = dataCollection.iloc[:, :-1].values\n",
    "y = dataCollection.iloc[:, -1].values\n",
    "\n",
    "# one-hot encode the output variable\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# convert labels to one-hot encoding\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "y = y.reshape(len(y), 1)\n",
    "y = ohe.fit_transform(y)\n",
    "\n",
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# pad the sequences\n",
    "X_train = pad_sequences(X_train, maxlen=n_steps, padding='pre', truncating='pre', value=0)\n",
    "X_test = pad_sequences(X_test, maxlen=n_steps, padding='pre', truncating='pre', value=0)\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_3_input to have 3 dimensions, but got array with shape (2298026, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, validation_data\u001b[39m=\u001b[39m(X_test, y_test))\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:854\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_call_args(\u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    853\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m--> 854\u001b[0m \u001b[39mreturn\u001b[39;00m func\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    855\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    856\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m    857\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    858\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    859\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m    860\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    861\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    862\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[0;32m    863\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[0;32m    864\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m    865\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m    866\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    867\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[0;32m    868\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m    869\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m    870\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[0;32m    871\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m    872\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m    873\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m    874\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training_arrays_v1.py:698\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[0;32m    675\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    676\u001b[0m     model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    693\u001b[0m ):\n\u001b[0;32m    694\u001b[0m     batch_size \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39m_validate_or_infer_batch_size(\n\u001b[0;32m    695\u001b[0m         batch_size, steps_per_epoch, x\n\u001b[0;32m    696\u001b[0m     )\n\u001b[1;32m--> 698\u001b[0m     x, y, sample_weights \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49m_standardize_user_data(\n\u001b[0;32m    699\u001b[0m         x,\n\u001b[0;32m    700\u001b[0m         y,\n\u001b[0;32m    701\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    702\u001b[0m         class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m    703\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    704\u001b[0m         check_steps\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         steps_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msteps_per_epoch\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    706\u001b[0m         steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m    707\u001b[0m         validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[0;32m    708\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m    709\u001b[0m     )\n\u001b[0;32m    711\u001b[0m     \u001b[39mif\u001b[39;00m validation_data:\n\u001b[0;32m    712\u001b[0m         val_x, val_y, val_sample_weights \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39m_prepare_validation_data(\n\u001b[0;32m    713\u001b[0m             validation_data, batch_size, validation_steps\n\u001b[0;32m    714\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:2650\u001b[0m, in \u001b[0;36mModel._standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2641\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2642\u001b[0m     \u001b[39mnot\u001b[39;00m run_eagerly\n\u001b[0;32m   2643\u001b[0m     \u001b[39mand\u001b[39;00m is_build_called\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2646\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(_is_symbolic_tensor(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m all_inputs)\n\u001b[0;32m   2647\u001b[0m ):\n\u001b[0;32m   2648\u001b[0m     \u001b[39mreturn\u001b[39;00m [], [], \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2650\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_standardize_tensors(\n\u001b[0;32m   2651\u001b[0m     x,\n\u001b[0;32m   2652\u001b[0m     y,\n\u001b[0;32m   2653\u001b[0m     sample_weight,\n\u001b[0;32m   2654\u001b[0m     run_eagerly\u001b[39m=\u001b[39;49mrun_eagerly,\n\u001b[0;32m   2655\u001b[0m     dict_inputs\u001b[39m=\u001b[39;49mdict_inputs,\n\u001b[0;32m   2656\u001b[0m     is_dataset\u001b[39m=\u001b[39;49mis_dataset,\n\u001b[0;32m   2657\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2658\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2659\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:2691\u001b[0m, in \u001b[0;36mModel._standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2688\u001b[0m \u001b[39m# Standardize the inputs.\u001b[39;00m\n\u001b[0;32m   2689\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset)):\n\u001b[0;32m   2690\u001b[0m     \u001b[39m# TODO(fchollet): run static checks with dataset output shape(s).\u001b[39;00m\n\u001b[1;32m-> 2691\u001b[0m     x \u001b[39m=\u001b[39m training_utils_v1\u001b[39m.\u001b[39;49mstandardize_input_data(\n\u001b[0;32m   2692\u001b[0m         x,\n\u001b[0;32m   2693\u001b[0m         feed_input_names,\n\u001b[0;32m   2694\u001b[0m         feed_input_shapes,\n\u001b[0;32m   2695\u001b[0m         check_batch_axis\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# Don't enforce the batch size.\u001b[39;49;00m\n\u001b[0;32m   2696\u001b[0m         exception_prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   2697\u001b[0m     )\n\u001b[0;32m   2699\u001b[0m \u001b[39m# Get typespecs for the input data and sanitize it if necessary.\u001b[39;00m\n\u001b[0;32m   2700\u001b[0m \u001b[39m# TODO(momernick): This should be capable of doing full input validation\u001b[39;00m\n\u001b[0;32m   2701\u001b[0m \u001b[39m# at all times - validate that this is so and refactor the\u001b[39;00m\n\u001b[0;32m   2702\u001b[0m \u001b[39m# standardization code.\u001b[39;00m\n\u001b[0;32m   2703\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset):\n",
      "File \u001b[1;32mc:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training_utils_v1.py:712\u001b[0m, in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    710\u001b[0m shape \u001b[39m=\u001b[39m shapes[i]\n\u001b[0;32m    711\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data_shape) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(shape):\n\u001b[1;32m--> 712\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    713\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError when checking \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    714\u001b[0m         \u001b[39m+\u001b[39m exception_prefix\n\u001b[0;32m    715\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m: expected \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    716\u001b[0m         \u001b[39m+\u001b[39m names[i]\n\u001b[0;32m    717\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m to have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    718\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(shape))\n\u001b[0;32m    719\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m dimensions, but got array with shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    720\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(data_shape)\n\u001b[0;32m    721\u001b[0m     )\n\u001b[0;32m    722\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m check_batch_axis:\n\u001b[0;32m    723\u001b[0m     data_shape \u001b[39m=\u001b[39m data_shape[\u001b[39m1\u001b[39m:]\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_3_input to have 3 dimensions, but got array with shape (2298026, 128)"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54a97a0fbc56a6bb929e10541f2d402cd83dcce5272985c7b44f056d8198dd01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
